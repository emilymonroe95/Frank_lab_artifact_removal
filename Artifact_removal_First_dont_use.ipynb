{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3269a673-25ef-4b1f-9321-fe68ddc57b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal of this notebook: Deconstruct code from schemas, and implement on a smaller scale with imported recording from extractor. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b8ac5c-53c5-43df-9b5b-6662b2ca8eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@schema #define a schema, which is/ will be a group of related tables \n",
    "class SpikeSortingArtifactDetectionParameters(dj.Manual): #table creation, manually adding information to it. This table will hold the parameters for artifact detection. \n",
    "    #each set of parameters will have a name and a dictionary that contains the parameters, which will be used in the below function.  \n",
    "    definition = \"\"\"\n",
    "    # Table for holding parameters related to artifact detection\n",
    "    # Note that\n",
    "    artifact_parameter_name: varchar(200) #name for this set of parameters \n",
    "    ---\n",
    "    parameter_dict: BLOB    # dictionary of parameters for get_no_artifact_times() function\n",
    "    \"\"\"\n",
    "\n",
    "    def insert_default(self): #This will run if there are no arguments to original class?\n",
    "        #first, insert the default, none, into the table. this contains the parameters that will likely not have any imapct on data. \n",
    "        \"\"\"Insert the default artifact parameters ('none') with a appropriate parameter dict .\n",
    "        \"\"\"\n",
    "        param_dict = {} #empty dictionary called param_dict\n",
    "        param_dict['skip'] = True\n",
    "        param_dict['zscore_thresh'] = -1.0\n",
    "        param_dict['amplitude_thresh'] = -1.0\n",
    "        param_dict['proportion_above_thresh'] = -1.0\n",
    "        param_dict['zero_window_len'] = 30 # 1 ms at 30 KHz, but this is of course skipped\n",
    "        self.insert1({'artifact_parameter_name': 'none', 'parameter_dict' : param_dict},\n",
    "                        skip_duplicates=True)\n",
    "#self is a variable that points to the instance of the method you are working with. \n",
    "\n",
    "#Looks like this is a method that will actually find times with artifact and remove them. \n",
    "#Artifacts are defined as periods where the absolute amplitude of the signal exceeds one or both specified thresholds on the proportion of channels specified, with the period extended by the zero_window/2 samples on each side\n",
    "\n",
    "\n",
    "#SO this section will take the parameters (why are they hard coded here?) \n",
    "#And will return valid times. \n",
    "#DOnt have a primary key? \n",
    "\n",
    "\n",
    "#want this function to be tied to tables info\n",
    "#could go around other dj.manual tables, see what kinds of functions you see in them (do they fetch at the end, etc) \n",
    "#HOw functions are set up in python (regarding the hard coded things)- if you dont insert, it will default to the hard coded things  \n",
    "    #find a way to share notebook for us both to check unestanding \n",
    "    \n",
    "    def get_no_artifact_times(self, recording, zscore_thresh=-1.0, amplitude_thresh=-1.0, \n",
    "                              proportion_above_thresh=1.0, zero_window_len=1.0, skip: bool=True):\n",
    "        #Defines the parameters for artifact detection and their types. \n",
    "        \"\"\"returns an interval list of valid times, excluding detected artifacts found in data within recording extractor.\n",
    "        Artifacts are defined as periods where the absolute amplitude of the signal exceeds one\n",
    "        or both specified thresholds on the proportion of channels specified, with the period extended\n",
    "        by the zero_window/2 samples on each side\n",
    "        Threshold values <0 are ignored.\n",
    "\n",
    "        :param recording: recording extractor\n",
    "        :type recording: SpikeInterface recording extractor object\n",
    "        :param zscore_thresh: Stdev threshold for exclusion, defaults to -1.0\n",
    "        :type zscore_thresh: float, optional\n",
    "        :param amplitude_thresh: Amplitude threshold for exclusion, defaults to -1.0\n",
    "        :type amplitude_thresh: float, optional\n",
    "        :param proportion_above_thresh:\n",
    "        :type float, optional\n",
    "        :param zero_window_len: the width of the window in milliseconds to zero out (window/2 on each side of threshold crossing)\n",
    "        :type int, optional\n",
    "        :return: [array of valid times]\n",
    "        :type: [numpy array]\n",
    "        \"\"\"\n",
    "\n",
    "        # if no thresholds were specified, we return an array with the timestamps of the first and last samples\n",
    "        if zscore_thresh <= 0 and amplitude_thresh <= 0:\n",
    "            return np.asarray([[recording._timestamps[0], recording._timestamps[recording.get_num_frames()-1]]])\n",
    "       \n",
    "    #This is where the artifact detection and comparison to thresholds occurs. \n",
    "    \n",
    "    #use the specified window length (how long to zero out on either sde of the artifact based on sampling rate\n",
    "        \n",
    "        half_window_points = np.round(\n",
    "            recording.get_sampling_frequency() * 1000 * zero_window_len / 2)\n",
    "      \n",
    "    #User defines proportion of electrodes that have to be above threshold for it to be labeled artifact (but two diff versions of this?)\n",
    "    nelect_above = np.round(proportion_above_thresh * data.shape[0])\n",
    "    \n",
    "        # get the data traces\n",
    "        data = recording.get_traces()\n",
    "\n",
    "        # compute the number of electrodes that have to be above threshold based on the number of rows of data\n",
    "        nelect_above = np.round(\n",
    "            proportion_above_thresh * len(recording.get_channel_ids()))\n",
    "\n",
    "        # apply the amplitude threshold (find when the data is above amplitude threshold)\n",
    "        above_a = np.abs(data) > amplitude_thresh\n",
    "\n",
    "        # zscore the data and get the absolute value for thresholding\n",
    "        dataz = np.abs(stats.zscore(data, axis=1))\n",
    "        above_z = dataz > zscore_thresh #find when datas z scare is above specified threshold\n",
    "       \n",
    "    #not sure what ravel does. im guessing that it looks acrross electrodes(?) and finds when the sum of them being over thresh is bigger than neglect_above\n",
    "        above_both = np.ravel(np.argwhere(\n",
    "            np.sum(np.logical_and(above_z, above_a), axis=0) >= nelect_above))\n",
    "        valid_timestamps = recording._timestamps #not sure what this is doing yet.. why are these valid timesteps?\n",
    "        \n",
    "        # for each above threshold point, set the timestamps on either side of it to -1\n",
    "        #So, have a list of valid timesteps, and set times that are \"above both\" plus or minus window points to negative 1...\n",
    "        for a in above_both:\n",
    "            valid_timestamps[a - half_window_points:a +\n",
    "                             half_window_points] = -1\n",
    "\n",
    "        #anything that is not -1 is now a valid timestamp,     \n",
    "        # use get_valid_intervals to find all of the resulting valid times.\n",
    "        #What is get_valid_intervals? Look into these other arguments \n",
    "        #Go find get valid intervals \n",
    "        return get_valid_intervals(valid_timestamps[valid_timestamps != -1], recording.get_sampling_frequency(), 1.5, 0.001)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5720e1b3-76f3-4a27-af83-27395ba47870",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Okay first, make dictionary with parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fd1b30f-867a-4cd4-8869-9f1e9b28cb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip = True\n",
    "zscore_thresh = -1.0\n",
    "amplitude_thresh=-1.0\n",
    "proportion_above_thresh = -1.0\n",
    "zero_window_len=30\n",
    "\n",
    "\n",
    "param_dict = {} #empty dictionary called param_dict\n",
    "param_dict['skip'] = skip\n",
    "param_dict['zscore_thresh'] = zscore_thresh\n",
    "param_dict['amplitude_thresh'] = amplitude_thresh\n",
    "param_dict['proportion_above_thresh'] = proportion_above_thresh\n",
    "param_dict['zero_window_len'] = zero_window_len # 1 ms at 30 KHz, but this is of course skipped\n",
    "\n",
    "\n",
    "#self.insert1({'artifact_parameter_name': 'none', 'parameter_dict' : param_dict},skip_duplicates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d9e5e21-3576-474f-be29-d04105e4c0e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'skip': True,\n",
       " 'zscore_thresh': -1.0,\n",
       " 'amplitude_thresh': -1.0,\n",
       " 'proportion_above_thresh': -1.0,\n",
       " 'zero_window_len': 30}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd849244-bc0b-4df0-9a02-120f3291be33",
   "metadata": {},
   "outputs": [],
   "source": [
    "recording = 'some path'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf406f0-fc19-4b91-872b-99a3bc97006a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_no_artifact_times(self, recording, zscore_thresh=-1.0, amplitude_thresh=-1.0, \n",
    "                              proportion_above_thresh=1.0, zero_window_len=1.0, skip: bool=True):\n",
    "    #this just says whe to return the same timestamps. \n",
    "    if zscore_thresh <= 0 and amplitude_thresh <= 0:\n",
    "        return np.asarray([[recording._timestamps[0], recording._timestamps[recording.get_num_frames()-1]]])\n",
    "    #in \"deconstructing\" the code, I still have to use the other functions defined in detejoint. \n",
    "    #Should I still use the np packages? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27783e9-b8d8-4469-bca1-98f41be4949a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, populate spike sortng table with file \n",
    "(SpikeSortingRecording() & {'nwb_file_name' : nwb_file_name}).fetch1('recording_extractor_object')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc664ca-1f09-4cd9-8140-92199d1b4d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, define keys: \n",
    "\n",
    "\n",
    "key = dict()\n",
    "key['nwb_file_name'] = nwb_file_name\n",
    "key['sort_group_id'] = sort_group_id\n",
    "key['sort_interval_name'] = sort_interval_name\n",
    "key['interval_list_name'] = interval_list_name\n",
    "key['sorter_name'] ='mountainsort4'\n",
    "key['parameter_set_name'] = 'franklab_tetrode_hippocampus_30KHz'\n",
    "key['cluster_metrics_list_name'] ='franklab_cluster_metrics_09-19-2021'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3935e5-4548-4d2f-a33a-05515b2767a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the function to get recording extractor \n",
    "recording = SpikeSortingRecording().get_filtered_recording_extractor(key)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
